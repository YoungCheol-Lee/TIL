# 1. 훈련(Feature)와 테스트(Test)

- **머신러닝 과정**
1. 데이터 세트 분리
    - 데이터를 학습 데이터, 테스트 데이터로 분리
2. 모델 학습(fit)
    - 학습 데이터를 기반으로 머신러닝 알고리즘을 적용해 모델을 학습
3. 예측 수행(predict)
    - 학습된 머신러닝 모델을 이용해 테스트 데이터로 예측
4. 평가(evaluate)
    - `예측된 결괏값`과 `테스트 데이터`의 실제 결괏괎과 비교해 머신러닝 모델 성능을 평가

## 2. 데이터 세트
> 훈련 데이터 세트로 머신러닝 모델을 훈련 => 모든 학습/검증이 완료되고 최종 평가를 위해 테스트 데이터 세트 사용
- 전체 데이터 세트 = 훈련 데이터 세트(+검증 데이터 세트) + 테스트 데이터 세트

1. 훈련 데이터 세트
    - 머신러닝 알고리즘 학습을 위해 사용
    - 데이터 속성(Feature)와 결정값(Target, Label) 모두 가짐
    - 훈련 데이터를 기반으로 머신러닝 알고리즘이 데이터 속성(Feature)와 결정값(Target)의 `패턴`을 인지하고 `학습`
      - `.fit() 함수로 Data를 받아서 알고리즘에 적용시킴`

2. 테스트 데이터 세트
    - 훈련 데이터 세트에서 `학습한 머신러닝 알고리즘 테스트`
    - 테스트 데이터는 데이터 속성(Feature)만 머신러닝 알고리즘에 제공
    - 머신러닝 알고리즘이 속성 데이터(Feature)만을 기반으로 `결정값(y햇) 예측`
    - 테스트 데이터 = 학습 데이터와 별도의 데이터 세트로 제공 = `훈련 데이터를 테스트 데이터로 사용하면 안됨`
      - 일반화 오차: 테스트 데이터 세트에 대한 오차

### 2.1. 데이터 분할
![!\[train_test_split이란\](image.png)](%EC%9D%B4%EB%AF%B8%EC%A7%80%ED%8F%B4%EB%8F%84/train_test_split.png)

1. 분류
- Label(Target) 데이터 세트를 기준으로 분할
    - Label 데이터 사이에는 연관성이나 상관관계가 없음
- 랜덤이 필요한 이유
    - [0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2] 처럼 0, 1, 2가 1:1:1 비율로 있지만, 분할에 따라 특정 데이터 비율이 늘어날 수 있음
- Stratified Split(계층적 분할) 방식
    - 원본 데이터 비율을 훈련/테스트 세트에도 비슷한 비율로 분할
    - **`극단적 case`** 에서는 계층적 분할이 있어야 학습 세트에 놓치는 데이터가 없음
      - 0이 50개 1이 100만개 있을 때, `랜덤성이 있어도 훈련 데이터 세트에 1만 존재할 가능성`이 높음 = 계층적 분할로 0 데이터도 학습 필요
      - 또는 테스트 데이터 세트에 1만 존재한다면, 예측률이 1.0이 나오더라도 `0에 대한 테스트를 못하는 상황`이므로 매우 안좋은 모델
2. 회귀 
- feature 데이터 세트를 기준으로 분할
    - Label 데이터가 연속성 데이터(수치)이기 때문에 Label 데이터간의 상관관계 비교 가능
- 회귀의 Stratified Split(계층적 분할) 방식
    - feature 데이터의 구간을 나누고, 각 구간별 데이터 count의 비율로 계층적 분할

## 3. 교차검증
> 전체 데이터 세트 = 훈련 데이터 세트 + 테스트 데이터 세트   
> 훈련 데이터 세트 분할 => 훈련 데이터 세트 + 검증 데이터 세트
![!\[cross_val_score함수\](cross_val_score함수.png)](%EC%9D%B4%EB%AF%B8%EC%A7%80%ED%8F%B4%EB%8F%84/cross_val_score%ED%95%A8%EC%88%98.png)

1. K폴드(Fold) 교차 검증
- k=5 일 경우, 4개의 폴드 세트는 학습 + 나머지 1개의 폴드 세트는 검증 => 5번 반복
    - cross_val_score 함수(사이킷런): 교차검증 간편화

2. 하이퍼 파라미터 튜닝 GridSearchCV
- `GridSearchCV`를 이용하여 분류, 회귀 모델 알고리즘에 사용되는 `하이퍼 파라미터`를 순차 입력하면서 `최적의 파라미터`를 편하게 도출
    - 하이퍼 파라미터: 개발자가 직접 넣어줘야 하는 값(모델 성능 조절)
- GridSearch를 수행하기 위한 하이퍼 파라미터 정의
  - 딕셔너리를 활용하여 정의
  - 딕셔너리의 key: 하이퍼 파라미터의 이름(하이퍼 파라미터의 변수명)
  - 딕셔너리의 value: 하이퍼 파라미터에 들어갈 값의 목록(리스트로 정의)
- GridSearchCV로 훈련 수 = 폴드 수 * 하이퍼 파라미터 수
- GridSearch의 단점: 시간이 오래 걸림. CPU, RAM 등 많이 사용.