# 기하와 벡터

## 벡터
> N차원 벡터   
1. 벡터 a의 길이 = $\sqrt(a^Ta)$
2. 단위벡터(unit vector): 길이가 1인 벡터

### 벡터의 연산
1. 벡터의 연산
 - 합/차: 크기(N)가 같은 벡터의 합/차는 똑같이 크기가 N인 벡터가 나옴 = R<sup>N</sup>
 - 곱셈(내적): 벡터 x와 y의 곱 = x⋅y = <x,y> = x<sup>T</sup>y = R<sup>N</sup> = **스칼라**
   1. `1 x N 벡터와 N x 1 벡터의 곱은 N 스칼라 값이 나옴`
   2. `N x 1 벡터와 1 x N 벡터의 곱은 N x N 행렬이 나옴`
  - 유사도
     - 벡터1,2,3을 각각 v1*v2 = 1000이고, v1*v3=300 일 때, `v1은 v3보다 v2와 유사하다.`라는 유사도로 사용 가능 = `내적 값이 더 크면 더 유사한 데이터`

2. 벡터의 차
  - $a-b$는 `b의 시작점에서 a의 끝점`으로 가는 벡터를 의미
#### 유클리드 거리
> 두 벡터가 가리키는 점 사이의 거리 = `벡터의 차의 길이`

- $\parallel b-a \parallel = \parallel a \parallel^2 + \parallel b \parallel^2 -2a^Tb$ 

### 벡터의 내적
> <a, b> = $a^Tb$ = $\parallel a \parallel \parallel b \parallel cos\theta$   
> **벡터 간의 $\theta$가 작을 수록 내적값이 크기 때문에 `유사한 데이터`다.**
- **코사인 유사도**
  - **$\theta$가 작다 = $cos\theta$가 크다 = 내적값이 크다 = 유사한 데이터**

- **직교:** $a \perp b 는 cos\theta = cos 90$을 의미하므로 $a \perp b = 0$

### 투영성분과 직교성분
> 벡터 a는 벡터 b에 평행하는 성분과 직교하는 성분으로 분해할 수 있음   
> 투영성분(projection) = a<sup>$\parallel b$</sup>   
> 직교성분(rejection) = a<sup>$\perp b$</sup>

### 선형종속과 선형독립
- 선형 종속: 벡터의 집합을 `영벡터`로 만드는 `스칼라 계수`가 있는 벡터 집합
> $x_1, x_2,...x_N$인 벡터의 집합이 `영벡터`가 되도록 하는 스칼라 계수 $c_1, c_2,...c_N$들이 존재하면 `선형종속`이라고 함(단 스칼라계수 c가 전부 0인 경우는 제외)


- 선형독립: 벡터의 집합을 `영벡터`로 만드려면 `스칼라 계수`가 모두 0인 경우 밖에 없는 벡터집합
> 벡터들의 선형조합($x_1,x_2,..x_N$)이 0이 되게 하는 스칼라 계수($c_1 = c_2=...=c_N=0$)는 모두 0인 경우 밖에 없는 경우.

#### 다중공선성
> 특정 행렬X의 열벡터들이 선형종속 or 선형종속에 가까운 현상 = `열벡터들의 연관성이 너무 큼` = `머신러닝 성능이 매우 떨어짐`

1. 벡터의 개수가 벡터의 차원보다 클 경우
    - 행렬(R<sup>NxM</sup>)의 열의 개수(M)가 행의 개수(N)보다 클 경우
    - 선형 모델(ML)로서 성능이 매우 떨어짐(선형 종속이 되면 열벡터간의 유사도 분리가 어려움)
2. 값이 같은 벡터가 있는 경우
    - 동일한 벡터가 있으면 `반드시 선형종속` => ctrl c + ctrl v 주의하기!
3. **어떤 벡터가 다른 벡터의 선형조합일 경우**
    - N개의 벡터를 활용하여 특정한 X벡터를 만들 수 있으면 `선형종속`
 
#### 랭크 Rank
- 열랭크 또는 행랭크(Column, Row Rank)
> 행렬의 열(행)벡터 중 서로 독립인 열(행)벡터의 최대 개수. `열랭크와 행랭크는 항상 같음` = `3x4 행렬은 최대 Rank = 3`

### 벡터공간과 기저벡터
- 벡터공간, Vector Space(V)
> N개의 선형독립인 벡터들을 선형조합하여 만들어지는 모든 벡터의 집합   
- 기저벡터, Basis Vector
> 벡터공간을 만든 벡터   

**`N개의 N차원 벡터`($x_1, x_2,..x_N$)이 `선형독립`이면, 이를 선형 조합하여 모든 `N차원 벡터`를 만들 수 있다.**
- 정방행렬이 풀Rank면 역행렬이 존재한다 <=> 정방행렬이 역행렬이 존재하면 풀Rank다

### 벡터공간 투영